# Matrix multiplication on GPU - TorchScript

```elixir
Mix.install(
  [
    {:nx, "~> 0.4.0"},
    {:scidata, "~> 0.1.9"},
    # {:axon, "~> 0.3.0"},
    {:axon, git: "https://github.com/elixir-nx/nx"},
    {:torchx, "~> 0.3"}
    # {:torchx, git: "https://github.com/elixir-nx/nx/tree/main/torchx.git"}
  ],
  system_env: %{"LIBTORCH_TARGET" => "cu116"}
)
```

<!-- livebook:{"output":true} -->

```
Resolving Hex dependencies...
Dependency resolution completed:
Unchanged:
  complex 0.4.2
  earmark_parser 1.4.29
  ex_doc 0.29.0
  makeup 1.1.0
  makeup_elixir 0.16.0
  makeup_erlang 0.1.1
  nimble_parsec 1.2.3
All dependencies are up to date
Resolving Hex dependencies...
Dependency resolution completed:
Unchanged:
  benchee 1.1.0
  complex 0.4.2
  deep_merge 1.0.0
  earmark_parser 1.4.29
  elixir_make 0.6.3
  ex_doc 0.29.0
  makeup 1.1.0
  makeup_elixir 0.16.0
  makeup_erlang 0.1.1
  nimble_parsec 1.2.3
  statistex 1.0.0
  xla 0.3.0
Resolving Hex dependencies...
Dependency resolution completed:
Unchanged:
  complex 0.4.2
  dll_loader_helper 0.1.0
  earmark_parser 1.4.29
  elixir_make 0.6.2
  ex_doc 0.29.0
  makeup 1.1.0
  makeup_elixir 0.16.0
  makeup_erlang 0.1.1
  nimble_parsec 1.2.3
make[1]: Entering directory '/home/ml3/.cache/mix/installs/elixir-1.14.1-erts-13.1/637868f8f58944c68301b95956ceba47/deps/axon/exla'
make[1]: '/home/ml3/.cache/mix/installs/elixir-1.14.1-erts-13.1/637868f8f58944c68301b95956ceba47/deps/axon/exla/_build/dev/lib/exla/priv/libexla.so' is up to date.
make[1]: Leaving directory '/home/ml3/.cache/mix/installs/elixir-1.14.1-erts-13.1/637868f8f58944c68301b95956ceba47/deps/axon/exla'
make[1]: Entering directory '/home/ml3/.cache/mix/installs/elixir-1.14.1-erts-13.1/637868f8f58944c68301b95956ceba47/deps/axon/torchx'
make[1]: Leaving directory '/home/ml3/.cache/mix/installs/elixir-1.14.1-erts-13.1/637868f8f58944c68301b95956ceba47/deps/axon/torchx'
Unchecked dependencies for environment dev:
* axon (https://github.com/elixir-nx/nx)
  could not find an app file at "_build/dev/lib/axon/ebin/axon.app". This may happen if the dependency was not yet compiled or the dependency indeed has no app file (then you can pass app: false as option)
```

## Before running notebook

This notebook has a dependency on TorchScript. By default Torchx uses your CPU.  If you have direct access to an NVidia GPU, the notebook has a section on running matrix multiplication on a GPU.  According to the documentation, https://github.com/elixir-nx/nx/tree/main/torchx#readme Torchx will need to compile the TorchScript binding.  Before you run the above cell, you will need make/nmake, cmake (3.12+) and a C++ compiler.  The Windows binding to TorchScript is also supported and more information can be found at the Torchx readme. At this time, the MacOS binding doesn't support access to a GPU.

**Running the first cell compiles the binding to TorchScript.  On our system the compilation took about 10 minutes.  Switching to github nx took 20 minutes to compile**  At this time, making modifications to the Mix.install dependencies will result in a recomplilation.

The notebook is currently set up for an Nvidia GPU on Linux.

```
system_env: %{"LIBTORCH_TARGET" => "cu111"}
```

Feel free to read the Torchx documentation and modify to fit your needs.

## Experimenting with backend control

In this notebook, we are going to experiment with swapping out backends in the same notebook. We chose not to set the backend globally throughout the notebook. At the beginning of the notebook, we'll repeat the approach we used in 01a_matmul_using_CPU. We begin with the Elixir Binary backend. You'll see that it isn't quick multiplying 10,000 rows of MNIST data by some arbitrary weights.

[REPLACE] We'll then repeat the same multiplication using an NVidia 1080Ti GPU. The 1080 Ti is not the fastest GPU, but it is tremendously faster than a "large" set of data on the BinaryBackend.

31649.26 milliseconds using BinaryBackend with a CPU only.
0.14 milliseconds using XLA with a warmed up GPU
226,000 times faster on an old GPU

```elixir
# Without choosing a backend, Nx defaults to Nx.BinaryBackend
Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
{Nx.BinaryBackend, []}
```

```elixir
# Just in case you rerun the notebook, let's make sure the default backend is BinaryBackend
# Setting to the Nx default backend
# Nx.default_backend(Nx.BinaryBackend)
# Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
nil
```

```elixir
Nx.default_backend({Torchx.Backend, client: :host})
Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
{Torchx.Backend, [client: :host]}
```

We'll pull down the MNIST data again

```elixir
{train_images, train_labels} = Scidata.MNIST.download()
{test_images, test_labels} = Scidata.MNIST.download_test()
```

<!-- livebook:{"output":true} -->

```
{{<<0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...>>, {:u, 8}, {10000, 1, 28, 28}},
 {<<7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1,
    3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, ...>>, {:u, 8}, {10000}}}
```

```elixir
{train_images_binary, train_tensor_type, train_shape} = train_images
{test_images_binary, test_tensor_type, test_shape} = test_images
```

<!-- livebook:{"output":true} -->

```
{<<0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...>>, {:u, 8}, {10000, 1, 28, 28}}
```

```elixir
{train_tensor_type, test_tensor_type}
```

<!-- livebook:{"output":true} -->

```
{{:u, 8}, {:u, 8}}
```

Convert into Tensors and normalize to between 0 and 1

```elixir
train_tensors =
  train_images_binary
  |> Nx.from_binary(train_tensor_type)
  |> Nx.reshape({60000, 28 * 28})
  |> Nx.divide(255)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[60000][784]
  Torchx.Backend(cuda)
  [
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...],
    ...
  ]
>
```

We'll separate the data into 50,000 train images and 10,000 validation images.

```elixir
x_train = train_tensors[0..49_999]
x_valid = train_tensors[50_000..59_999]
{x_train.shape, x_valid.shape}
```

<!-- livebook:{"output":true} -->

```
{{50000, 784}, {10000, 784}}
```

Training is more stable when random numbers are initialized with a mean of 0.0 and a variance of 1.0

```elixir
mean = 0.0
variance = 1.0
weights = Nx.random_normal({784, 10}, mean, variance, type: {:f, 32})
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  Torchx.Backend(cuda)
  [
    [1.155038833618164, -0.14629486203193665, -1.1900442838668823, 0.9416877031326294, -1.1047000885009766, 1.027855634689331, -2.428539276123047, 1.1259475946426392, 1.8886574506759644, 0.6305360198020935],
    [-0.8702868819236755, 0.11186961829662323, 0.7241712212562561, 1.2778087854385376, 0.6156754493713379, -0.12945231795310974, -0.8437321782112122, 0.851854145526886, 0.3398282825946808, 0.17057514190673828],
    [0.5553203821182251, -0.5384835600852966, -0.6655512452125549, -0.1784447282552719, 0.4794098436832428, 0.42793431878089905, -0.21004442870616913, 0.506833016872406, 0.38388606905937195, 0.5851215124130249],
    [0.28607699275016785, 0.44128158688545227, -0.5463770031929016, -0.26711568236351013, 0.11892851442098618, 0.35395368933677673, -0.8490606546401978, 0.8240422010421753, -0.08638741821050644, -0.9989067316055298],
    [0.830651581287384, -1.9350743293762207, -0.040810853242874146, 0.12548504769802094, -0.2749152183532715, 0.48937544226646423, 1.2289535999298096, -0.12059236317873001, 0.3427973985671997, 1.3755848407745361],
    ...
  ]
>
```

```elixir
large_nx_mult_fn = fn -> Nx.dot(x_valid, weights) end
```

<!-- livebook:{"output":true} -->

```
#Function<43.3316493/0 in :erl_eval.expr/6>
```

```elixir
repeat = fn timed_fn, times -> Enum.each(1..times, fn _x -> timed_fn.() end) end
```

<!-- livebook:{"output":true} -->

```
#Function<41.3316493/2 in :erl_eval.expr/6>
```

```elixir
# repeat_times = 5
# {elapsed_time_micro, _} = :timer.tc(repeat, [large_nx_mult_fn, repeat_times])
# avg_elapsed_time_ms = elapsed_time_micro / 1000 / repeat_times

# {backend, _device} = Nx.default_backend()

# "#{backend} CPU avg time in #{avg_elapsed_time_ms} milliseconds  total_time #{elapsed_time_micro / 1000} milliseconds"
```

<!-- livebook:{"output":true} -->

```
nil
```

```elixir
# Nx.default_backend({Torchx.Backend, client: :host})
# Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
nil
```

```elixir
# x_valid_torchx_cpu = Nx.backend_transfer(x_valid, {Torchx.Backend, client: :host})
# weights_torchx_cpu = Nx.backend_transfer(weights, {Torchx.Backend, client: :host})
```

<!-- livebook:{"output":true} -->

```
nil
```

```elixir
# torchx_cpu_mult_fn = fn -> Nx.dot(x_valid_torchx_cpu, weights_torchx_cpu) end
torchx_cpu_mult_fn = fn -> Nx.dot(x_valid, weights) end
```

<!-- livebook:{"output":true} -->

```
#Function<43.3316493/0 in :erl_eval.expr/6>
```

```elixir
repeat_times = 5
{elapsed_time_micro, _} = :timer.tc(repeat, [torchx_cpu_mult_fn, repeat_times])
avg_elapsed_time_ms = elapsed_time_micro / 1000 / repeat_times

{backend, [device: device]} = Nx.default_backend()

"#{backend} #{device} avg time in milliseconds #{avg_elapsed_time_ms} total_time #{elapsed_time_micro / 1000}"
```

```elixir
Nx.default_backend({Torchx.Backend, device: :cuda})
Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
{Torchx.Backend, [device: :cuda]}
```

```elixir
# x_valid_cuda = Nx.backend_transfer(x_valid, {Torchx.Backend, client: :cuda})
# weights_cuda = Nx.backend_transfer(weights, {Torchx.Backend, client: :cuda})
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  Torchx.Backend(cuda)
  [
    [-0.9650636315345764, -0.8534107208251953, -0.4562549293041229, 1.6015528440475464, -0.99657142162323, -0.2366049885749817, -0.21041712164878845, -0.5706636905670166, -2.608386754989624, -0.7514076232910156],
    [0.020734218880534172, -0.308178573846817, -0.8019789457321167, 0.38143491744995117, -1.299706220626831, 1.4440377950668335, 0.5244581699371338, 0.836944580078125, -0.6307716965675354, -1.2875291109085083],
    [-0.9640306234359741, -0.6825852990150452, 1.0563740730285645, -1.179348111152649, 0.16545476019382477, 0.49104368686676025, -1.5404492616653442, 0.14259232580661774, 1.0131930112838745, 2.0037009716033936],
    [-0.9532591104507446, 1.2549127340316772, -0.7655459642410278, -0.8037842512130737, -0.4887266457080841, 0.07325591892004013, -0.3364439308643341, -0.5606346726417542, 0.15698231756687164, -0.297625333070755],
    [-1.9274179935455322, 0.25347700715065, 0.006314158905297518, 1.4953982830047607, 0.3794085681438446, -0.5028500556945801, -0.5738266706466675, 0.6606372594833374, 1.1527702808380127, -0.0026525037828832865],
    ...
  ]
>
```

```elixir
# torchx_gpu_mult_fn = fn -> Nx.dot(x_valid_cuda, weights_cuda) end
```

<!-- livebook:{"output":true} -->

```
#Function<43.3316493/0 in :erl_eval.expr/6>
```

```elixir
# repeat_times = 5
# {elapsed_time_micro, _} = :timer.tc(repeat, [torchx_gpu_mult_fn, repeat_times])
# avg_elapsed_time_ms = elapsed_time_micro / 1000 / repeat_times

# {backend, [device: device]} = Nx.default_backend()

# "#{backend} #{device} avg time in milliseconds #{avg_elapsed_time_ms} total_time #{elapsed_time_micro / 1000}"
```

<!-- livebook:{"output":true} -->

```
"Elixir.Torchx.Backend cuda avg time in milliseconds 0.0546 total_time 0.273"
```

```elixir
# x_valid = Nx.backend_transfer(x_valid_cuda, Nx.BinaryBackend)
# weights = Nx.backend_transfer(weights_cuda, Nx.BinaryBackend)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  [
    [-0.9650636315345764, -0.8534107208251953, -0.4562549293041229, 1.6015528440475464, -0.99657142162323, -0.2366049885749817, -0.21041712164878845, -0.5706636905670166, -2.608386754989624, -0.7514076232910156],
    [0.020734218880534172, -0.308178573846817, -0.8019789457321167, 0.38143491744995117, -1.299706220626831, 1.4440377950668335, 0.5244581699371338, 0.836944580078125, -0.6307716965675354, -1.2875291109085083],
    [-0.9640306234359741, -0.6825852990150452, 1.0563740730285645, -1.179348111152649, 0.16545476019382477, 0.49104368686676025, -1.5404492616653442, 0.14259232580661774, 1.0131930112838745, 2.0037009716033936],
    [-0.9532591104507446, 1.2549127340316772, -0.7655459642410278, -0.8037842512130737, -0.4887266457080841, 0.07325591892004013, -0.3364439308643341, -0.5606346726417542, 0.15698231756687164, -0.297625333070755],
    [-1.9274179935455322, 0.25347700715065, 0.006314158905297518, 1.4953982830047607, 0.3794085681438446, -0.5028500556945801, -0.5738266706466675, 0.6606372594833374, 1.1527702808380127, -0.0026525037828832865],
    ...
  ]
>
```
