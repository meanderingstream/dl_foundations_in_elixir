# Matrix multiplication on GPU - EXLA

```elixir
Mix.install(
  [
    {:nx, "~> 0.4.0"},
    {:scidata, "~> 0.1.9"},
    {:axon, "~> 0.3.0"},
    {:exla, "~> 0.4"}
  ],
  system_env: %{"XLA_TARGET" => "cuda111"}
)
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Experimenting with backend control

```elixir
# Without choosing a backend, Nx defaults to Nx.BinaryBackend
Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
{Nx.BinaryBackend, []}
```

```elixir
# Just in case you rerun the notebook, let's make sure the default backend is BinaryBackend
# Setting to the Nx default backend
Nx.default_backend(Nx.BinaryBackend)
Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
{Nx.BinaryBackend, []}
```

```elixir
{train_images, train_labels} = Scidata.MNIST.download()
{test_images, test_labels} = Scidata.MNIST.download_test()
```

<!-- livebook:{"output":true} -->

```
{{<<0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...>>, {:u, 8}, {10000, 1, 28, 28}},
 {<<7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1,
    3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, ...>>, {:u, 8}, {10000}}}
```

```elixir
{train_images_binary, train_tensor_type, train_shape} = train_images
{test_images_binary, test_tensor_type, test_shape} = test_images
```

<!-- livebook:{"output":true} -->

```
{<<0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...>>, {:u, 8}, {10000, 1, 28, 28}}
```

```elixir
{train_tensor_type, test_tensor_type}
```

<!-- livebook:{"output":true} -->

```
{{:u, 8}, {:u, 8}}
```

```elixir
train_tensors =
  train_images_binary
  |> Nx.from_binary(train_tensor_type)
  |> Nx.reshape({60000, 28 * 28})
  |> Nx.divide(255)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[60000][784]
  [
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...],
    ...
  ]
>
```

```elixir
x_train_cpu = train_tensors[0..49_999]
x_valid_cpu = train_tensors[50_000..59_999]
{x_train_cpu.shape, x_valid_cpu.shape}
```

<!-- livebook:{"output":true} -->

```
{{50000, 784}, {10000, 784}}
```

```elixir
mean = 0.0
variance = 1.0
weights_cpu = Nx.random_normal({784, 10}, mean, variance, type: {:f, 32})
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  [
    [-1.2300676107406616, -1.1997238397598267, -1.9952067136764526, 1.0617443323135376, -1.4041376113891602, -0.2182314097881317, 1.4686073064804077, 2.1602230072021484, 1.1015342473983765, -0.6608599424362183],
    [-1.3111447095870972, 2.4684436321258545, -0.3749065399169922, -0.06131727993488312, 0.05180155485868454, 0.42293089628219604, -0.7537996172904968, -0.35125917196273804, 1.0763864517211914, 0.18233363330364227],
    [-1.611325979232788, -0.666179358959198, -1.4290579557418823, 1.454958200454712, 0.22783735394477844, -0.7801699042320251, 0.2435704618692398, -0.6871567368507385, -0.7277348041534424, 0.10037553310394287],
    [-0.7115886807441711, -0.5177516937255859, 1.1852874755859375, -0.195032998919487, -0.7827126383781433, 0.240373432636261, -0.11045489460229874, 0.7962868213653564, -0.0027189296670258045, -1.1320666074752808],
    [-1.185189127922058, 0.6095731854438782, -1.2220104932785034, -0.22155828773975372, -1.3718606233596802, 0.510450005531311, -0.5407333970069885, -1.4425822496414185, -0.7442138195037842, -1.880690336227417],
    ...
  ]
>
```

```elixir
large_nx_mult_fn = fn -> Nx.dot(x_valid_cpu, weights_cpu) end
```

<!-- livebook:{"output":true} -->

```
#Function<43.3316493/0 in :erl_eval.expr/6>
```

```elixir
repeat = fn timed_fn, times -> Enum.each(1..times, fn _x -> timed_fn.() end) end
```

<!-- livebook:{"output":true} -->

```
#Function<41.3316493/2 in :erl_eval.expr/6>
```

```elixir
repeat_times = 5
# Warm up one iteration
{elapsed_time_micro, _} = :timer.tc(repeat, [large_nx_mult_fn, repeat_times])
avg_elapsed_time_ms = elapsed_time_micro / 1000 / repeat_times

{backend, _device} = Nx.default_backend()

"#{backend} CPU avg time in #{avg_elapsed_time_ms} milliseconds, total_time #{elapsed_time_micro / 1000} milliseconds"
```

<!-- livebook:{"output":true} -->

```
"Elixir.Nx.BinaryBackend CPU avg time in 31988.8336 milliseconds, total_time 159944.168 milliseconds"
```

```elixir
Nx.default_backend({EXLA.Backend, client: :host})
Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
{EXLA.Backend, [client: :host]}
```

```elixir
x_valid_exla = Nx.backend_transfer(x_valid_cpu, {EXLA.Backend, client: :host})
weights_exla = Nx.backend_transfer(weights_cpu, {EXLA.Backend, client: :host})
```

<!-- livebook:{"output":true} -->

```

15:19:33.536 [info] XLA service 0x7f839811d380 initialized for platform Host (this does not guarantee that XLA will be used). Devices:

15:19:33.539 [info]   StreamExecutor device (0): Host, Default Version

```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  EXLA.Backend<host:0, 0.1877786681.1509556256.239031>
  [
    [-1.2300676107406616, -1.1997238397598267, -1.9952067136764526, 1.0617443323135376, -1.4041376113891602, -0.2182314097881317, 1.4686073064804077, 2.1602230072021484, 1.1015342473983765, -0.6608599424362183],
    [-1.3111447095870972, 2.4684436321258545, -0.3749065399169922, -0.06131727993488312, 0.05180155485868454, 0.42293089628219604, -0.7537996172904968, -0.35125917196273804, 1.0763864517211914, 0.18233363330364227],
    [-1.611325979232788, -0.666179358959198, -1.4290579557418823, 1.454958200454712, 0.22783735394477844, -0.7801699042320251, 0.2435704618692398, -0.6871567368507385, -0.7277348041534424, 0.10037553310394287],
    [-0.7115886807441711, -0.5177516937255859, 1.1852874755859375, -0.195032998919487, -0.7827126383781433, 0.240373432636261, -0.11045489460229874, 0.7962868213653564, -0.0027189296670258045, -1.1320666074752808],
    [-1.185189127922058, 0.6095731854438782, -1.2220104932785034, -0.22155828773975372, -1.3718606233596802, 0.510450005531311, -0.5407333970069885, -1.4425822496414185, -0.7442138195037842, -1.880690336227417],
    ...
  ]
>
```

```elixir
exla_mult_fn = fn -> Nx.dot(x_valid_exla, weights_exla) end
```

<!-- livebook:{"output":true} -->

```
#Function<43.3316493/0 in :erl_eval.expr/6>
```

```elixir
repeat_times = 5
# Warm up one iteration
{elapsed_time_micro, _} = :timer.tc(repeat, [exla_mult_fn, repeat_times])
{elapsed_time_micro, _} = :timer.tc(repeat, [exla_mult_fn, repeat_times])
avg_elapsed_time_ms = elapsed_time_micro / 1000 / repeat_times

{backend, _device} = Nx.default_backend()

"#{backend} CPU avg time in #{avg_elapsed_time_ms} milliseconds, total_time #{elapsed_time_micro / 1000} milliseconds"
```

<!-- livebook:{"output":true} -->

```

15:19:33.698 [info] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero

15:19:33.698 [info] XLA service 0x7f8398114770 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:

15:19:33.698 [info]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1

15:19:33.698 [info] Using BFC allocator.

15:19:33.698 [info] XLA backend allocating 10414463385 bytes on device 0 for BFCAllocator.

15:19:34.312 [error] Execution of replica 0 failed: INVALID_ARGUMENT: Buffer passed to Execute() as argument 0 to replica 0 is on device cpu:0, but replica is assigned to device gpu:0.

```

```elixir
# x_valid_cpu = Nx.backend_transfer(x_valid_xla)
# weights_cpu = Nx.backend_transfer(weights_xla)
```

<!-- livebook:{"output":true} -->

```
nil
```

```elixir
Nx.default_backend({EXLA.Backend, device: :cuda})
Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
{EXLA.Backend, [device: :cuda]}
```

```elixir
x_valid_cuda = Nx.backend_transfer(x_valid_exla, {EXLA.Backend, client: :cuda})
weights_cuda = Nx.backend_transfer(weights_exla, {EXLA.Backend, client: :cuda})
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  EXLA.Backend<cuda:0, 0.1877786681.1509556256.239048>
  [
    [-1.2300676107406616, -1.1997238397598267, -1.9952067136764526, 1.0617443323135376, -1.4041376113891602, -0.2182314097881317, 1.4686073064804077, 2.1602230072021484, 1.1015342473983765, -0.6608599424362183],
    [-1.3111447095870972, 2.4684436321258545, -0.3749065399169922, -0.06131727993488312, 0.05180155485868454, 0.42293089628219604, -0.7537996172904968, -0.35125917196273804, 1.0763864517211914, 0.18233363330364227],
    [-1.611325979232788, -0.666179358959198, -1.4290579557418823, 1.454958200454712, 0.22783735394477844, -0.7801699042320251, 0.2435704618692398, -0.6871567368507385, -0.7277348041534424, 0.10037553310394287],
    [-0.7115886807441711, -0.5177516937255859, 1.1852874755859375, -0.195032998919487, -0.7827126383781433, 0.240373432636261, -0.11045489460229874, 0.7962868213653564, -0.0027189296670258045, -1.1320666074752808],
    [-1.185189127922058, 0.6095731854438782, -1.2220104932785034, -0.22155828773975372, -1.3718606233596802, 0.510450005531311, -0.5407333970069885, -1.4425822496414185, -0.7442138195037842, -1.880690336227417],
    ...
  ]
>
```

```elixir
exla_gpu_mult_fn = fn -> Nx.dot(x_valid_cuda, weights_cuda) end
```

<!-- livebook:{"output":true} -->

```
#Function<43.3316493/0 in :erl_eval.expr/6>
```

```elixir
repeat_times = 5
# Warm up one iteration
{elapsed_time_micro, _} = :timer.tc(repeat, [exla_gpu_mult_fn, repeat_times])
{elapsed_time_micro, _} = :timer.tc(repeat, [exla_gpu_mult_fn, repeat_times])
avg_elapsed_time_ms = elapsed_time_micro / 1000 / repeat_times

{backend, [device: device]} = Nx.default_backend()
# backend
# # "#{backend} #{device}"
# IO.inspect(device)
"#{backend} #{device} avg time in #{avg_elapsed_time_ms} milliseconds total_time #{elapsed_time_micro / 1000} milliseconds"
```

<!-- livebook:{"output":true} -->

```
"Elixir.EXLA.Backend cuda avg time in 0.1462 milliseconds total_time 0.731 milliseconds"
```

```elixir
x_valid_xla = Nx.backend_transfer(x_valid_cuda, {EXLA.Backend, client: :host})
weights_xla = Nx.backend_transfer(weights_cuda, {EXLA.Backend, client: :host})
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  EXLA.Backend<host:0, 0.1877786681.1509556256.239060>
  [
    [-1.2300676107406616, -1.1997238397598267, -1.9952067136764526, 1.0617443323135376, -1.4041376113891602, -0.2182314097881317, 1.4686073064804077, 2.1602230072021484, 1.1015342473983765, -0.6608599424362183],
    [-1.3111447095870972, 2.4684436321258545, -0.3749065399169922, -0.06131727993488312, 0.05180155485868454, 0.42293089628219604, -0.7537996172904968, -0.35125917196273804, 1.0763864517211914, 0.18233363330364227],
    [-1.611325979232788, -0.666179358959198, -1.4290579557418823, 1.454958200454712, 0.22783735394477844, -0.7801699042320251, 0.2435704618692398, -0.6871567368507385, -0.7277348041534424, 0.10037553310394287],
    [-0.7115886807441711, -0.5177516937255859, 1.1852874755859375, -0.195032998919487, -0.7827126383781433, 0.240373432636261, -0.11045489460229874, 0.7962868213653564, -0.0027189296670258045, -1.1320666074752808],
    [-1.185189127922058, 0.6095731854438782, -1.2220104932785034, -0.22155828773975372, -1.3718606233596802, 0.510450005531311, -0.5407333970069885, -1.4425822496414185, -0.7442138195037842, -1.880690336227417],
    ...
  ]
>
```
