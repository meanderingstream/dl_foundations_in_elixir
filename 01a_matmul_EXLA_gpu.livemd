# Matrix multiplication on GPU - EXLA

```elixir
Mix.install(
  [
    {:nx, "~> 0.4.0"},
    {:scidata, "~> 0.1.9"},
    {:axon, "~> 0.3.0"},
    {:exla, "~> 0.4"}
  ],
  system_env: %{"XLA_TARGET" => "cuda111"}
)
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Experimenting with backend control

```elixir
# Without choosing a backend, Nx defaults to Nx.BinaryBackend
Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
{Nx.BinaryBackend, []}
```

```elixir
# Just in case you rerun the notebook, let's make sure the default backend is BinaryBackend
# Setting to the Nx default backend
Nx.default_backend(Nx.BinaryBackend)
Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
{Nx.BinaryBackend, []}
```

```elixir
{train_images, train_labels} = Scidata.MNIST.download()
{test_images, test_labels} = Scidata.MNIST.download_test()
```

<!-- livebook:{"output":true} -->

```
{{<<0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...>>, {:u, 8}, {10000, 1, 28, 28}},
 {<<7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1,
    3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, ...>>, {:u, 8}, {10000}}}
```

```elixir
{train_images_binary, train_tensor_type, train_shape} = train_images
{test_images_binary, test_tensor_type, test_shape} = test_images
```

<!-- livebook:{"output":true} -->

```
{<<0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...>>, {:u, 8}, {10000, 1, 28, 28}}
```

```elixir
{train_tensor_type, test_tensor_type}
```

<!-- livebook:{"output":true} -->

```
{{:u, 8}, {:u, 8}}
```

```elixir
train_tensors =
  train_images_binary
  |> Nx.from_binary(train_tensor_type)
  |> Nx.reshape({60000, 28 * 28})
  |> Nx.divide(255)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[60000][784]
  [
    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...],
    ...
  ]
>
```

```elixir
x_train = train_tensors[0..49_999]
x_valid = train_tensors[50_000..59_999]
{x_train.shape, x_valid.shape}
```

<!-- livebook:{"output":true} -->

```
{{50000, 784}, {10000, 784}}
```

```elixir
mean = 0.0
variance = 1.0
weights = Nx.random_normal({784, 10}, mean, variance, type: {:f, 32})
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  [
    [1.5105571746826172, 0.4004764258861542, 0.11976490914821625, -0.3693736791610718, -0.507191002368927, -0.7037718892097473, -0.4972197413444519, -1.2505477666854858, -0.6247710585594177, -1.190390944480896],
    [-0.09479938447475433, 0.3056424856185913, -0.7049371600151062, 0.6013796329498291, 0.14702850580215454, -0.04713498055934906, 0.9355850219726562, -0.9855000972747803, 1.3926557302474976, -1.5649769306182861],
    [-0.20776581764221191, -0.957975447177887, -1.7929104566574097, 1.0544246435165405, -0.18552613258361816, -0.21043051779270172, 0.32169944047927856, -0.8453061580657959, 0.14144790172576904, -0.12043311446905136],
    [-0.10379252582788467, -0.0738130584359169, 0.7687478065490723, 0.15937353670597076, -1.6199783086776733, 0.2655268907546997, 0.4717308282852173, 1.8391849994659424, 0.5992400646209717, -1.1259535551071167],
    [-0.9209828972816467, 0.4360388517379761, -0.9503656625747681, 1.8811677694320679, 1.7487798929214478, -0.8021900653839111, 1.6337368488311768, 0.09953863173723221, 1.6472444534301758, -0.6815526485443115],
    ...
  ]
>
```

```elixir
large_nx_mult_fn = fn -> Nx.dot(x_valid, weights) end
```

<!-- livebook:{"output":true} -->

```
#Function<43.3316493/0 in :erl_eval.expr/6>
```

```elixir
repeat = fn timed_fn, times -> Enum.each(1..times, fn _x -> timed_fn.() end) end
```

<!-- livebook:{"output":true} -->

```
#Function<41.3316493/2 in :erl_eval.expr/6>
```

```elixir
repeat_times = 5
{elapsed_time_micro, _} = :timer.tc(repeat, [large_nx_mult_fn, repeat_times])
avg_elapsed_time_ms = elapsed_time_micro / 1000 / repeat_times

{backend, _device} = Nx.default_backend()

"#{backend} CPU avg time in #{avg_elapsed_time_ms} milliseconds, total_time #{elapsed_time_micro / 1000} milliseconds"
```

<!-- livebook:{"output":true} -->

```
"Elixir.Nx.BinaryBackend CPU avg time in 31350.2098 milliseconds, total_time 156751.049 milliseconds"
```

```elixir
Nx.default_backend(EXLA.Backend)
Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
{EXLA.Backend, []}
```

```elixir
x_valid = Nx.backend_transfer(x_valid, EXLA.Backend)
weights = Nx.backend_transfer(weights, EXLA.Backend)
```

<!-- livebook:{"output":true} -->

```

13:23:00.572 [info] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero

13:23:00.575 [info] XLA service 0x7fafc000cfc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:

13:23:00.575 [info]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1

13:23:00.576 [info] Using BFC allocator.

13:23:00.576 [info] XLA backend allocating 10414463385 bytes on device 0 for BFCAllocator.

```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  EXLA.Backend<cuda:0, 0.1836086292.1759903774.252806>
  [
    [1.5105571746826172, 0.4004764258861542, 0.11976490914821625, -0.3693736791610718, -0.507191002368927, -0.7037718892097473, -0.4972197413444519, -1.2505477666854858, -0.6247710585594177, -1.190390944480896],
    [-0.09479938447475433, 0.3056424856185913, -0.7049371600151062, 0.6013796329498291, 0.14702850580215454, -0.04713498055934906, 0.9355850219726562, -0.9855000972747803, 1.3926557302474976, -1.5649769306182861],
    [-0.20776581764221191, -0.957975447177887, -1.7929104566574097, 1.0544246435165405, -0.18552613258361816, -0.21043051779270172, 0.32169944047927856, -0.8453061580657959, 0.14144790172576904, -0.12043311446905136],
    [-0.10379252582788467, -0.0738130584359169, 0.7687478065490723, 0.15937353670597076, -1.6199783086776733, 0.2655268907546997, 0.4717308282852173, 1.8391849994659424, 0.5992400646209717, -1.1259535551071167],
    [-0.9209828972816467, 0.4360388517379761, -0.9503656625747681, 1.8811677694320679, 1.7487798929214478, -0.8021900653839111, 1.6337368488311768, 0.09953863173723221, 1.6472444534301758, -0.6815526485443115],
    ...
  ]
>
```

```elixir
exla_mult_fn = fn -> Nx.dot(x_valid, weights) end
```

<!-- livebook:{"output":true} -->

```
#Function<43.3316493/0 in :erl_eval.expr/6>
```

```elixir
repeat_times = 5
{elapsed_time_micro, _} = :timer.tc(repeat, [exla_mult_fn, repeat_times])
avg_elapsed_time_ms = elapsed_time_micro / 1000 / repeat_times

{backend, _device} = Nx.default_backend()

"#{backend} CPU avg time in #{avg_elapsed_time_ms} milliseconds, total_time #{elapsed_time_micro / 1000} milliseconds"
```

<!-- livebook:{"output":true} -->

```
"Elixir.EXLA.Backend CPU avg time in 100.6748 milliseconds, total_time 503.374 milliseconds"
```

```elixir
x_valid = Nx.backend_transfer(x_valid)
weights = Nx.backend_transfer(weights)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  [
    [1.5105571746826172, 0.4004764258861542, 0.11976490914821625, -0.3693736791610718, -0.507191002368927, -0.7037718892097473, -0.4972197413444519, -1.2505477666854858, -0.6247710585594177, -1.190390944480896],
    [-0.09479938447475433, 0.3056424856185913, -0.7049371600151062, 0.6013796329498291, 0.14702850580215454, -0.04713498055934906, 0.9355850219726562, -0.9855000972747803, 1.3926557302474976, -1.5649769306182861],
    [-0.20776581764221191, -0.957975447177887, -1.7929104566574097, 1.0544246435165405, -0.18552613258361816, -0.21043051779270172, 0.32169944047927856, -0.8453061580657959, 0.14144790172576904, -0.12043311446905136],
    [-0.10379252582788467, -0.0738130584359169, 0.7687478065490723, 0.15937353670597076, -1.6199783086776733, 0.2655268907546997, 0.4717308282852173, 1.8391849994659424, 0.5992400646209717, -1.1259535551071167],
    [-0.9209828972816467, 0.4360388517379761, -0.9503656625747681, 1.8811677694320679, 1.7487798929214478, -0.8021900653839111, 1.6337368488311768, 0.09953863173723221, 1.6472444534301758, -0.6815526485443115],
    ...
  ]
>
```

```elixir
Nx.default_backend({EXLA.Backend, device: :cuda})
Nx.default_backend()
```

<!-- livebook:{"output":true} -->

```
{EXLA.Backend, [device: :cuda]}
```

```elixir
x_valid = Nx.backend_transfer(x_valid, {EXLA.Backend, client: :cuda})
weights = Nx.backend_transfer(weights, {EXLA.Backend, client: :cuda})
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  EXLA.Backend<cuda:0, 0.1836086292.1759903774.252826>
  [
    [1.5105571746826172, 0.4004764258861542, 0.11976490914821625, -0.3693736791610718, -0.507191002368927, -0.7037718892097473, -0.4972197413444519, -1.2505477666854858, -0.6247710585594177, -1.190390944480896],
    [-0.09479938447475433, 0.3056424856185913, -0.7049371600151062, 0.6013796329498291, 0.14702850580215454, -0.04713498055934906, 0.9355850219726562, -0.9855000972747803, 1.3926557302474976, -1.5649769306182861],
    [-0.20776581764221191, -0.957975447177887, -1.7929104566574097, 1.0544246435165405, -0.18552613258361816, -0.21043051779270172, 0.32169944047927856, -0.8453061580657959, 0.14144790172576904, -0.12043311446905136],
    [-0.10379252582788467, -0.0738130584359169, 0.7687478065490723, 0.15937353670597076, -1.6199783086776733, 0.2655268907546997, 0.4717308282852173, 1.8391849994659424, 0.5992400646209717, -1.1259535551071167],
    [-0.9209828972816467, 0.4360388517379761, -0.9503656625747681, 1.8811677694320679, 1.7487798929214478, -0.8021900653839111, 1.6337368488311768, 0.09953863173723221, 1.6472444534301758, -0.6815526485443115],
    ...
  ]
>
```

```elixir
exla_gpu_mult_fn = fn -> Nx.dot(x_valid, weights) end
```

<!-- livebook:{"output":true} -->

```
#Function<43.3316493/0 in :erl_eval.expr/6>
```

```elixir
repeat_times = 5
{elapsed_time_micro, _} = :timer.tc(repeat, [exla_gpu_mult_fn, repeat_times])
avg_elapsed_time_ms = elapsed_time_micro / 1000 / repeat_times

{backend, [device: device]} = Nx.default_backend()
# backend
# # "#{backend} #{device}"
# IO.inspect(device)
"#{backend} #{device} avg time in #{avg_elapsed_time_ms} milliseconds total_time #{elapsed_time_micro / 1000} milliseconds"
```

<!-- livebook:{"output":true} -->

```
"Elixir.EXLA.Backend cuda avg time in 0.1442 milliseconds total_time 0.721 milliseconds"
```

```elixir
x_valid = Nx.backend_transfer(x_valid)
weights = Nx.backend_transfer(weights)
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[784][10]
  [
    [1.5105571746826172, 0.4004764258861542, 0.11976490914821625, -0.3693736791610718, -0.507191002368927, -0.7037718892097473, -0.4972197413444519, -1.2505477666854858, -0.6247710585594177, -1.190390944480896],
    [-0.09479938447475433, 0.3056424856185913, -0.7049371600151062, 0.6013796329498291, 0.14702850580215454, -0.04713498055934906, 0.9355850219726562, -0.9855000972747803, 1.3926557302474976, -1.5649769306182861],
    [-0.20776581764221191, -0.957975447177887, -1.7929104566574097, 1.0544246435165405, -0.18552613258361816, -0.21043051779270172, 0.32169944047927856, -0.8453061580657959, 0.14144790172576904, -0.12043311446905136],
    [-0.10379252582788467, -0.0738130584359169, 0.7687478065490723, 0.15937353670597076, -1.6199783086776733, 0.2655268907546997, 0.4717308282852173, 1.8391849994659424, 0.5992400646209717, -1.1259535551071167],
    [-0.9209828972816467, 0.4360388517379761, -0.9503656625747681, 1.8811677694320679, 1.7487798929214478, -0.8021900653839111, 1.6337368488311768, 0.09953863173723221, 1.6472444534301758, -0.6815526485443115],
    ...
  ]
>
```
